{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Dataset Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, We will use **SVM** (Support Verctor Machine) model which is used in classification of supervised learning. SVC of python has 2 options either linear or polynomial kernel (there is more of kernel types). We will use both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Iris Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, We will load the iris dataset & set up the base variables (data & target)\n",
    "1. Import `datasets` from `sklearn`\n",
    "2. Import `StandardScaler` from `sklearn.preprocessing`\n",
    "3. Use `load_iris()` in `datasets` to load the iris dataset into a variable & name it `iris`\n",
    "4. Standardize the data of iris `iris.data` using `fit_transform` of `StandardScaler`\n",
    "5. Load the new standardized data into variable & name it `X`\n",
    "6. Load the new standardized target `iris.target` into variable & name it `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris Dataset Has Been Loaded Successfully!\n",
      "Data Has Been Standardized Successfully!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "print('Iris Dataset Has Been Loaded Successfully!')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "iris.data = scaler.fit_transform(iris.data, iris.target)\n",
    "print('Data Has Been Standardized Successfully!')\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up The Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USELESS PART & SHOULD BE ABANDONED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_iris = pd.DataFrame(X)\n",
    "df_iris[len(df_iris.columns)] = y\n",
    "\n",
    "df_iris.columns = np.append(iris.feature_names, 'class')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperating Train & Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, We will seperate the training & testing sets\n",
    "1. Import `train_test_split` from `sklearn.model_selection`\n",
    "2. Use `train_test_split` to split the data & target (dont forget to set `random_state` parameter to some constant to avoid inconsistent outputs in different runs & set `test_size` to be 0.2 (to split the dataset into 2 parts 80% for training & 20% for testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.2)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining C Hyperparameter Test Function (Linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, We will make a function that will use grid search to find the most suitable combination of parameters to obtain the highest accuracy (since this is linear we will have only 1 hyperparamter which is C (if you want to know more about c, google it))\n",
    "\n",
    "1. Import `ShuffleSplit` from `sklearn.model_selection`\n",
    "2. Import `GreadSearchCV` from `sklearn.model_selection`\n",
    "3. Import `LinearSVC` from `sklearn.svm`\n",
    "4. Define a function with the following signature `grid_linear_svc_test(X, y, c)` where X is the data, y is target & c is a numpy array with the values of c that we grid search to test (note: the bigger the range of c the more time it will take)\n",
    "5. Define `ShuffleSplit` object (don't forget to set `random_state` parameter & set `test_size` to 0.2)\n",
    "6. Define `LinearSVC` object with `loss` parameter set to `hinge` (`random_state` xD)\n",
    "7. Make a dictionary with key named `C` and set its value to the passed parameter of the function `c`\n",
    "8. Define `GridSearchCV` object and pass `LinearSVC` as `estimator` & the dictionary that contains `C` as `param_grid` & `ShuffleSplit` as `cv`\n",
    "9. Fit the passed `X` & `y` in the `GridSearchCV` using `fit` function\n",
    "10. Return `GridSearchCV` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def grid_linear_svc_test(X, y, c):\n",
    "    print('Initiating Grid Search of Linear SVC To Find Most Suitable C')\n",
    "    \n",
    "    cv_sets = ShuffleSplit(test_size = 0.20, random_state = 0)\n",
    "    svc = LinearSVC(loss='hinge', random_state=0)\n",
    "    params = {'C': c}\n",
    "    grid = GridSearchCV(svc, params, cv=cv_sets)\n",
    "    print('Testing C:', c)\n",
    "    \n",
    "    grid = grid.fit(X, y)\n",
    "    print('Grid Search of Linear SVC Is Done!')\n",
    "    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating C Values & Testing Them On The Training Set (Linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, We will generate numpy arrays that contain possible values of C & do grid search on them\n",
    "1. Pass the data & target of the training set with the array of `c` to the above function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating Grid Search of Linear SVC To Find Most Suitable C\n",
      "Testing C: [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536, 131072, 262144, 524288, 1048576]\n",
      "Grid Search of Linear SVC Is Done!\n",
      "Initiating Grid Search of Linear SVC To Find Most Suitable C\n",
      "Testing C: [128. 129. 130. 131. 132. 133. 134. 135. 136. 137. 138. 139. 140. 141.\n",
      " 142. 143. 144. 145. 146. 147. 148. 149. 150. 151. 152. 153. 154. 155.\n",
      " 156. 157. 158. 159. 160. 161. 162. 163. 164. 165. 166. 167. 168. 169.\n",
      " 170. 171. 172. 173. 174. 175. 176. 177. 178. 179. 180. 181. 182. 183.\n",
      " 184. 185. 186. 187. 188. 189. 190. 191. 192. 193. 194. 195. 196. 197.\n",
      " 198. 199. 200. 201. 202. 203. 204. 205. 206. 207. 208. 209. 210. 211.\n",
      " 212. 213. 214. 215. 216. 217. 218. 219. 220. 221. 222. 223. 224. 225.\n",
      " 226. 227. 228. 229. 230. 231. 232. 233. 234. 235. 236. 237. 238. 239.\n",
      " 240. 241. 242. 243. 244. 245. 246. 247. 248. 249. 250. 251. 252. 253.\n",
      " 254. 255. 256. 257. 258. 259. 260. 261. 262. 263. 264. 265. 266. 267.\n",
      " 268. 269. 270. 271. 272. 273. 274. 275. 276. 277. 278. 279. 280. 281.\n",
      " 282. 283. 284. 285. 286. 287. 288. 289. 290. 291. 292. 293. 294. 295.\n",
      " 296. 297. 298. 299. 300. 301. 302. 303. 304. 305. 306. 307. 308. 309.\n",
      " 310. 311. 312. 313. 314. 315. 316. 317. 318. 319. 320. 321. 322. 323.\n",
      " 324. 325. 326. 327. 328. 329. 330. 331. 332. 333. 334. 335. 336. 337.\n",
      " 338. 339. 340. 341. 342. 343. 344. 345. 346. 347. 348. 349. 350. 351.\n",
      " 352. 353. 354. 355. 356. 357. 358. 359. 360. 361. 362. 363. 364. 365.\n",
      " 366. 367. 368. 369. 370. 371. 372. 373. 374. 375. 376. 377. 378. 379.\n",
      " 380. 381. 382. 383. 384. 385. 386. 387. 388. 389. 390. 391. 392. 393.\n",
      " 394. 395. 396. 397. 398. 399. 400. 401. 402. 403. 404. 405. 406. 407.\n",
      " 408. 409. 410. 411. 412. 413. 414. 415. 416. 417. 418. 419. 420. 421.\n",
      " 422. 423. 424. 425. 426. 427. 428. 429. 430. 431. 432. 433. 434. 435.\n",
      " 436. 437. 438. 439. 440. 441. 442. 443. 444. 445. 446. 447. 448. 449.\n",
      " 450. 451. 452. 453. 454. 455. 456. 457. 458. 459. 460. 461. 462. 463.\n",
      " 464. 465. 466. 467. 468. 469. 470. 471. 472. 473. 474. 475. 476. 477.\n",
      " 478. 479. 480. 481. 482. 483. 484. 485. 486. 487. 488. 489. 490. 491.\n",
      " 492. 493. 494. 495. 496. 497. 498. 499. 500. 501. 502. 503. 504. 505.\n",
      " 506. 507. 508. 509. 510. 511.]\n",
      "Grid Search of Linear SVC Is Done!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def generate_polynomials(base, min_exp, max_exp):\n",
    "    output = []\n",
    "    for i in np.arange(min_exp, max_exp+1):\n",
    "        if(i > 0):\n",
    "            output += [base**i]\n",
    "    return output\n",
    "\n",
    "c = generate_polynomials(2, 1, 20)\n",
    "grid = grid_linear_svc_test(X_train, y_train, c)\n",
    "\n",
    "left_boundry_exp = math.log(grid.best_estimator_.C, 2) - 1\n",
    "right_boundry_exp = math.log(grid.best_estimator_.C, 2) + 1\n",
    "\n",
    "c = np.arange(math.pow(2, left_boundry_exp), math.pow(2, right_boundry_exp), 1)\n",
    "grid = grid_linear_svc_test(X_train, y_train, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying Best C & Best Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C    : 507.0\n",
      "Best Score: 95.41666666666667 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Best C    :\", grid.best_estimator_.C)\n",
    "print(\"Best Score:\", grid.best_score_ * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set Score (Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Score 96.66666666666667 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Set Score\", grid.best_estimator_.score(X_test, y_test) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Polynomial SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def grid_poly_svc_test(X, y, c, degree, coef0):\n",
    "    cv_sets = ShuffleSplit(test_size = 0.20, random_state = 0)\n",
    "    svc = SVC(kernel=\"poly\", random_state=0)\n",
    "    params = {'C': c, \"degree\": degree, \"coef0\": coef0}\n",
    "    grid = GridSearchCV(svc, params, cv=cv_sets)\n",
    "    grid = grid.fit(X, y)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating C Values & Testing Them On The Training Set (Polynomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.logspace(-10, 11, base=2)\n",
    "degree = np.arange(2, 10, 1)\n",
    "coef0 = np.arange(-10, 11, 1)\n",
    "\n",
    "grid = grid_poly_svc_test(X_train, y_train, c, degree, coef0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying Best C & Best Degree & Best Coef0 & Best Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C     : 0.37149857228423705\n",
      "Best Degree: 3\n",
      "Best Coef0 : 1\n",
      "Best Score : 96.66666666666667 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Best C     :\", grid.best_estimator_.C)\n",
    "print(\"Best Degree:\", grid.best_estimator_.degree)\n",
    "print(\"Best Coef0 :\", grid.best_estimator_.coef0)\n",
    "print(\"Best Score :\", grid.best_score_ * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set  (Polynomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Score 100.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Set Score\", grid.best_estimator_.score(X_test, y_test) * 100, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
